{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 08:32:44.799373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AdamW, get_linear_schedule_with_warmup, AutoModelForMaskedLM, AutoConfig, AutoTokenizer, DataCollatorWithPadding)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained-model\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'she', 'goes', 'school', 'by', '[', 'h', '##l', ']', 'bus', '[', '/', 'h', '##l', ']', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer test\n",
    "input_text = \"[CLS] She goes school by [HL] bus [/HL] [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(input_text,add_special_tokens=False)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'she', 'goes', 'school', 'by', '[HL]', 'bus', '[/HL]', '[SEP]']\n",
      "Embedding(30522, 768, padding_idx=0)\n",
      "Embedding(30524, 768)\n"
     ]
    }
   ],
   "source": [
    "# add [HL], [/HL] token \n",
    "added_token_num = tokenizer.add_special_tokens({\"additional_special_tokens\":[\"[HL]\",\"[/HL]\"]})\n",
    "tokenized_text = tokenizer.tokenize(input_text,add_special_tokens=False)\n",
    "print(tokenized_text)\n",
    "\n",
    "# add token number\n",
    "print(model.get_input_embeddings())\n",
    "model.resize_token_embeddings(tokenizer.vocab_size + added_token_num)\n",
    "print(model.get_input_embeddings()) # 2개 증가 된 것을 확인 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "file_path = \"./data/squad_nqg/train.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Heresy is any provocative belief or theory that is strongly at variance with established beliefs or customs. A heretic is a proponent of such claims or beliefs. Heresy is distinct from both apostasy, which is the explicit renunciation of one's religion, principles or cause, and blasphemy, which is an impious utterance or action concerning God or sacred things.\", 'question': 'What is heresy mainly at odds with?', 'answers': [{'answer_start': 77, 'text': 'established beliefs or customs'}]}\n"
     ]
    }
   ],
   "source": [
    "# sampling data\n",
    "print(data[0])\n",
    "\n",
    "input_text = data[0]['context']\n",
    "target_text = data[0]['question']\n",
    "\n",
    "# input_text = \"[CLS] Jane's favorite food is [HL] chicken [/HL] [SEP]\"\n",
    "# target_text = \"What is Jane's favorite food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Heresy is any provocative belief or theory that is strongly at variance with  [HL] established beliefs or customs [/HL] . A heretic is a proponent of such claims or beliefs. Heresy is distinct from both apostasy, which is the explicit renunciation of one's religion, principles or cause, and blasphemy, which is an impious utterance or action concerning God or sacred things. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# add [HL], [/HL]\n",
    "\n",
    "cls_token = tokenizer.cls_token\n",
    "sep_token = tokenizer.sep_token\n",
    "mask_token = tokenizer.mask_token\n",
    "\n",
    "\n",
    "answer_start = data[0]['answers'][0]['answer_start']\n",
    "answer = data[0]['answers'][0]['text']\n",
    "\n",
    "add_hl = f\"{cls_token} {data[0]['context'][:answer_start]} [HL] {data[0]['context'][answer_start:answer_start+len(answer)]} [/HL] {data[0]['context'][answer_start+len(answer):]} {sep_token}\"\n",
    "print(add_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   101,  4869,  1005,  1055,  5440,  2833,  2003, 30522,  7975,\n",
       "         30523,   102,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence = tokenizer(\n",
    "            \"[CLS] Jane's favorite food is [HL] chicken [/HL] [SEP]\",\n",
    "            padding=True,  # 문장의 길이가 짧다면 padding\n",
    "            truncation=True,  # 문장이 길다면 truncate\n",
    "            max_length=512,\n",
    "            return_token_type_ids=True,  # roberta 모델에서는 False\n",
    "            return_tensors=\"pt\",  # Tensor로 반환!\n",
    "        )\n",
    "\n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token = tokenizer.cls_token\n",
    "sep_token = tokenizer.sep_token\n",
    "mask_token = tokenizer.mask_token\n",
    "\n",
    "train_pickle = './squad_train.pickle'\n",
    "\n",
    "if os.path.isfile(train_pickle):\n",
    "    with open(train_pickle, 'rb') as f:\n",
    "        example_list = pickle.load(f)\n",
    "    print('*** finished to load train pickle file!')\n",
    "    \n",
    "else:       \n",
    "    example_list = []\n",
    "\n",
    "    for d in tqdm(data[:len(data)], desc = \"making pickle file...: \"):\n",
    "        example_pair = dict()\n",
    "        target_text = d['question']\n",
    "        answer_start = d['answers'][0]['answer_start']\n",
    "        answers = d['answers'][0]['text']\n",
    "        input_text = f\"{cls_token} {d['context'][:answer_start]} [HL] {d['context'][answer_start:answer_start+len(answer)]} [/HL] {d['context'][answer_start+len(answer):]} {sep_token}\"\n",
    "        tokenized_target = tokenizer.tokenize(target_text) # tokenize question\n",
    "        tokenized_text = tokenizer.tokenize(input_text,add_special_tokens=False)\n",
    "        if len(tokenized_target + tokenized_text) + 2 >= 512:\n",
    "            continue\n",
    "        \n",
    "        for i in range(0,len(tokenized_target)+1):\n",
    "            # tokenized\n",
    "            \n",
    "            tokenized_text.extend(tokenized_target[:i]) # tokenized_context + tokenized_question[:i]\n",
    "            tokenized_text.append(mask_token) # tokenized_context + tokenized_question[:i] + [MASK]\n",
    "            indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "            #tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "        \n",
    "            # label\n",
    "            #loss_ids = [0] * (len(tokenizer.convert_tokens_to_ids(tokenized_text))-1)\n",
    "            loss_ids = indexed_tokens.copy()\n",
    "            \n",
    "            if i == len(tokenized_target):\n",
    "                loss_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sep_token))[0])\n",
    "            else:\n",
    "                loss_ids.append(tokenizer.convert_tokens_to_ids(tokenized_target[i]))\n",
    "\n",
    "            loss_tensors = torch.tensor([loss_ids]).to(device)\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "            decodes_ids = tokenizer.decode(input_ids)\n",
    "            example_pair[decodes_ids] = loss_tensors\n",
    "            # print(tokenized_text,loss_ids,loss_ids[-1])\n",
    "            # print(len(indexed_tokens),len(loss_tensors))\n",
    "            \n",
    "        example_list.append(example_pair)\n",
    "        \n",
    "    with open(train_pickle,'wb') as f:\n",
    "        pickle.dump(example_list, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75612"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75612/75612 [00:00<00:00, 220049.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001690 1001690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 문장 list\n",
    "train_sentences = []\n",
    "# 정답 list\n",
    "train_label = []\n",
    "\n",
    "for examples in tqdm(example_list):\n",
    "    train_sentences.extend(list(examples.keys()))\n",
    "    train_label.extend(list(examples.values()))\n",
    "        \n",
    "print(len(train_sentences), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] heresy is any provocative belief or theory that is strongly at variance with [HL] established beliefs or customs [/HL]. a heretic is a proponent of such claims or beliefs. heresy is distinct from both apostasy, which is the explicit renunciation of one's religion, principles or cause, and blasphemy, which is an impious utterance or action concerning god or sacred things. [SEP] [MASK]\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bjaypark/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m     tokenized_sentence \u001b[39m=\u001b[39m tokenizer(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bjaypark/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m         data,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bjaypark/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m         padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \u001b[39m# 문장의 길이가 짧다면 padding\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bjaypark/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb#ch0000011vscode-remote?line=8'>9</a>\u001b[0m         add_special_tokens\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjaypark/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb#ch0000011vscode-remote?line=9'>10</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjaypark/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb#ch0000011vscode-remote?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenized_sentence\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bjaypark/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb#ch0000011vscode-remote?line=12'>13</a>\u001b[0m train_tokenized \u001b[39m=\u001b[39m tokenized_dataset(train_sentences)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "def tokenized_dataset(data):  # data: 문장 list\n",
    "    tokenized_sentence = tokenizer(\n",
    "        data,\n",
    "        padding=True,  # 문장의 길이가 짧다면 padding\n",
    "        truncation=True,  # 문장이 길다면 truncate\n",
    "        max_length=512,\n",
    "        return_token_type_ids=True,  # roberta 모델에서는 False\n",
    "        return_tensors=\"pt\",  # Tensor로 반환!\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    return tokenized_sentence\n",
    "\n",
    "train_tokenized = tokenized_dataset(train_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_tokenized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bjaypark/home/ubuntu/minji/BERT-Question-Generation/bert_generate.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m pad_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_tokenized[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m11781\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_tokenized' is not defined"
     ]
    }
   ],
   "source": [
    "pad_len = len(train_tokenized['input_ids'][11781])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30945/30945 [00:02<00:00, 11788.00it/s]\n"
     ]
    }
   ],
   "source": [
    "train_label_list = []\n",
    "for tl in tqdm(train_label):\n",
    "    target = torch.zeros(pad_len)\n",
    "    try:\n",
    "        target[:len(tl[0])]=tl[0]\n",
    "    except:\n",
    "        target = tl[0][:-1]\n",
    "    train_label_list.append(target.tolist())\n",
    "    \n",
    "train_label_list = torch.tensor(train_label_list).int()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 28354,  2003,  ...,     0,     0,     0],\n",
       "        [  101, 28354,  2003,  ...,     0,     0,     0],\n",
       "        [  101, 28354,  2003,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2076,  2023,  ...,     0,     0,     0],\n",
       "        [  101,  2076,  2023,  ...,     0,     0,     0],\n",
       "        [  101,  2076,  2023,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 28354,  2003,  ...,     0,     0,     0],\n",
       "        [  101, 28354,  2003,  ...,     0,     0,     0],\n",
       "        [  101, 28354,  2003,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2076,  2023,  ...,     0,     0,     0],\n",
       "        [  101,  2076,  2023,  ...,     0,     0,     0],\n",
       "        [  101,  2076,  2023,  ...,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized['labels'] = train_label_list.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 10\n",
    "weight_decay = 0.0\n",
    "learning_rate = 5e-5\n",
    "adam_epsilon = 1e-8\n",
    "max_grad_norm = 1.0\n",
    "warmup_steps = 0.0\n",
    "batch_size = 8\n",
    "max_steps = -1\n",
    "gradient_accumulation_steps = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(Dataset):\n",
    "    def __init__(self, data):  # tokenized 된 것과 라벨이 들어옴\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):  # data의 전체 길이\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.data.items()}\n",
    "        #item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    SquadDataset(train_tokenized), shuffle=False, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "t_total = len(train_tokenized) // gradient_accumulation_steps * num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 28354,  2003,  ...,     0,     0,     0],\n",
      "        [  101, 28354,  2003,  ...,     0,     0,     0],\n",
      "        [  101, 28354,  2003,  ...,     0,     0,     0],\n",
      "        [  101, 28354,  2003,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[  101, 28354,  2003,  ...,     0,     0,     0],\n",
      "        [  101, 28354,  2003,  ...,     0,     0,     0],\n",
      "        [  101, 28354,  2003,  ...,     0,     0,     0],\n",
      "        [  101, 28354,  2003,  ...,     0,     0,     0]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([4, 467]),\n",
       " 'token_type_ids': torch.Size([4, 467]),\n",
       " 'attention_mask': torch.Size([4, 467]),\n",
       " 'labels': torch.Size([4, 467])}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py38mj/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "{\n",
    "\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "\"weight_decay\": weight_decay,\n",
    "},\n",
    "{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": weight_decay},\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 15.3917 | step 0: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 15.39171028137207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 10.5941 | step 0: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 : 10.594099998474121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 7.8155 | step 0: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 : 7.815539836883545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 6.4056 | step 0: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 : 6.405588150024414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss 5.7463 | step 0: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 : 5.746278762817383\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    eveloss = 0\n",
    "    train_loader = tqdm(train_dataloader, desc='Loading train dataset')\n",
    "    for j, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)#k,labels=v)\n",
    "        loss = outputs.loss\n",
    "        eveloss += loss.mean().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loader.set_description(\"Loss %.04f | step %d\" % (loss, j))\n",
    "            \n",
    "    torch.save(model.state_dict(), f'model_weights_{epoch}_{eveloss}.pth')\n",
    "    print(\"epoch \"+ str(epoch) + \" : \" + str(eveloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "beb60ce440686e9521c933e15e80d2dc682d823aa040f9c343cc6f5ccd198a32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38mj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
